{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8058a73-020a-4f6a-81d4-06223194d231",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters\n",
    "\n",
    "__Attention__:   \n",
    "    This approach can be used for some super small neural nets. Because we're basically trying to bruteforce the right combination. \n",
    "    \n",
    "    There are other packages for Keras e.g. Hyperas, Hyperopt,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1b9299-ed3e-44c9-b7d7-138238bb93c2",
   "metadata": {},
   "source": [
    "## The underlying idea\n",
    "\n",
    "We gonna wrap our models into Sklearn models so that we can use the RandomizedSearch and GridSearch functions there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db1f17-45a8-4081-a455-1067433cefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af2ef83-1ac8-4b31-9194-67bea886a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden = 1, n_neurons = 30, learning_rate = 3e-3, input_shape = [9]): \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(name= \"input\"))\n",
    "    # model.add(keras.layers.InputLayer(input_shape = input_shape))\n",
    "    for i in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = keras.activations.relu))\n",
    "        \n",
    "    model.add(keras.layers.Dense(1, name= \"output\"))\n",
    "    model.compile(optimizer = keras.optimizers.SGD(learning_rate = learning_rate), loss = \"mse\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62321ad-0c32-4bb2-9110-53b57ff339d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Wrapper around Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc508d2-452e-4143-b6b0-edc01aa76803",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e0cea6-d680-404d-8bc7-84bf0eae1cc7",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e03391-05fc-4162-bf0f-1af9d61c73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76fa12-4058-4f56-8821-847e18a6d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation Dataset is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d5fe23-feb1-4e97-804d-6f6b98cbfa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aaa5d6-1386-4625-8867-a19028255728",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_train = x_train[:5000], x_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d01bc0-a579-4bb8-a863-163546752326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the validation dataset from the training data. We use 5000 the rest will be used for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263d236-090f-44a5-b2c9-38dfe1665d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938f2ad-de16-4a21-a93d-a4feca683e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We should scale our data because we're gonna use Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3c67d-22c8-4ca4-bf95-990c07ba622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_train, x_test = x_valid/255, x_train/255, x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a51bb2-2f2d-48ec-b09e-fda74b17abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Scikit-Learn to fit, predict and hyperparamter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "54314889-11fe-40f5-9bd0-972ab25e1277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 1s 778us/step - loss: 2.4200 - val_loss: 2.0003\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 1s 742us/step - loss: 1.8157 - val_loss: 1.6706\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 1s 739us/step - loss: 1.6925 - val_loss: 1.9905\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 1s 727us/step - loss: 1.6165 - val_loss: 1.5594\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 1s 728us/step - loss: 1.5641 - val_loss: 1.6163\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 1s 732us/step - loss: 1.5126 - val_loss: 1.5113\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 1s 737us/step - loss: 1.4733 - val_loss: 1.7293\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 1s 737us/step - loss: 1.4422 - val_loss: 1.4453\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 1s 729us/step - loss: 1.4116 - val_loss: 1.4692\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 1s 735us/step - loss: 1.3844 - val_loss: 1.4256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27d61152828>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(x_train, y_train, epochs = 10, validation_data = (x_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c35927b3-5184-45c4-8398-b108059afa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 554us/step - loss: 1.5150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.5149667263031006"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a561d42e-5b1f-44d7-a770-0c4b7c1e0392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.7330155 , 2.5430045 , 0.90628546], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.predict(x_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adefb11-12a6-4a23-b997-406f46b52f19",
   "metadata": {},
   "source": [
    "## Hyperparamter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "05edc45f-1c58-4a1b-a4e6-56f6571ee9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a594b23d-dbc9-42a7-9383-c15e6733d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_hidden\": [5,3,2],\n",
    "    \"n_neurons\": np.arange(20),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1bb4c89c-abc8-4205-92b2-4c1752bbde19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search = RandomizedSearchCV(keras_reg, params, n_iter=10, cv=3) # n_iter: number of paramter setting that are sampled, cv: Cross Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "853498cf-ad6e-4a0d-902b-6f91c63ca496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 815us/step - loss: 3.2895 - val_loss: 2.2259\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 735us/step - loss: 2.1295 - val_loss: 1.9364A: 0s - loss: 2.1\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 760us/step - loss: 1.9245 - val_loss: 1.8368\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 727us/step - loss: 1.8131 - val_loss: 1.7491\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 755us/step - loss: 1.7398 - val_loss: 1.6954\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 734us/step - loss: 1.6868 - val_loss: 1.6562\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 724us/step - loss: 1.6394 - val_loss: 1.7180\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 754us/step - loss: 1.6075 - val_loss: 1.6276\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 752us/step - loss: 1.5840 - val_loss: 1.5845\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 728us/step - loss: 1.5551 - val_loss: 1.6603\n",
      "573/573 [==============================] - 0s 456us/step - loss: 1.6502\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 785us/step - loss: 3.0579 - val_loss: 2.3530\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 719us/step - loss: 2.1196 - val_loss: 2.0048\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 721us/step - loss: 1.9777 - val_loss: 1.9727\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 710us/step - loss: 1.8933 - val_loss: 1.8664\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 735us/step - loss: 1.8456 - val_loss: 1.8106\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 729us/step - loss: 1.7898 - val_loss: 1.7814\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 708us/step - loss: 1.7427 - val_loss: 1.7957\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 714us/step - loss: 1.6989 - val_loss: 1.6934\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 710us/step - loss: 1.6670 - val_loss: 1.6722\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 707us/step - loss: 1.6350 - val_loss: 1.7336\n",
      "573/573 [==============================] - 0s 484us/step - loss: 1.7660\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 759us/step - loss: 3.1452 - val_loss: 2.1558\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 686us/step - loss: 2.0879 - val_loss: 1.8888\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 692us/step - loss: 1.9305 - val_loss: 1.8244\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 689us/step - loss: 1.8413 - val_loss: 1.7655\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 697us/step - loss: 1.7828 - val_loss: 1.7362\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 728us/step - loss: 1.7310 - val_loss: 1.9018\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 694us/step - loss: 1.6973 - val_loss: 1.6401\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 728us/step - loss: 1.6610 - val_loss: 1.6528\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 721us/step - loss: 1.6331 - val_loss: 1.5852\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 697us/step - loss: 1.6102 - val_loss: 1.6497\n",
      "573/573 [==============================] - 0s 488us/step - loss: 1.6913\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 839us/step - loss: 2.6390 - val_loss: 1.8703\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 758us/step - loss: 1.8851 - val_loss: 1.8621\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 776us/step - loss: 1.7429 - val_loss: 1.6656\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 768us/step - loss: 1.6560 - val_loss: 1.6630\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 768us/step - loss: 1.5872 - val_loss: 1.5800\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 766us/step - loss: 1.5397 - val_loss: 1.5082\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 777us/step - loss: 1.4969 - val_loss: 1.5061\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 771us/step - loss: 1.4609 - val_loss: 1.4577\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 802us/step - loss: 1.4175 - val_loss: 1.5007\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 769us/step - loss: 1.3913 - val_loss: 1.4301\n",
      "573/573 [==============================] - 0s 514us/step - loss: 1.4595\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 860us/step - loss: 2.5587 - val_loss: 1.8447\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 806us/step - loss: 1.8570 - val_loss: 1.6960\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 816us/step - loss: 1.7144 - val_loss: 1.6757\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 828us/step - loss: 1.6326 - val_loss: 1.6594\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 822us/step - loss: 1.5847 - val_loss: 1.5939\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 808us/step - loss: 1.5353 - val_loss: 1.6173\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 803us/step - loss: 1.5048 - val_loss: 1.5264\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 807us/step - loss: 1.4688 - val_loss: 1.4979\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 796us/step - loss: 1.4491 - val_loss: 1.4700\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 807us/step - loss: 1.4213 - val_loss: 1.4597\n",
      "573/573 [==============================] - 0s 511us/step - loss: 1.4892\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 3.1195 - val_loss: 2.0749\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 839us/step - loss: 2.0207 - val_loss: 1.8454\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 876us/step - loss: 1.8225 - val_loss: 1.7197\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 810us/step - loss: 1.7025 - val_loss: 1.6569\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 805us/step - loss: 1.6201 - val_loss: 1.5726\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 804us/step - loss: 1.5568 - val_loss: 1.5581\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 800us/step - loss: 1.5063 - val_loss: 1.5130\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 809us/step - loss: 1.4781 - val_loss: 1.5384\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 803us/step - loss: 1.4438 - val_loss: 1.4739\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 811us/step - loss: 1.4124 - val_loss: 1.5662\n",
      "573/573 [==============================] - 0s 519us/step - loss: 1.5877\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 800us/step - loss: 3.6114 - val_loss: 2.9393\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 785us/step - loss: 2.8777 - val_loss: 2.6016\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 828us/step - loss: 2.6806 - val_loss: 2.3262\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 783us/step - loss: 2.6294 - val_loss: 3.1357\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 720us/step - loss: 2.5933 - val_loss: 2.2528\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 724us/step - loss: 2.5656 - val_loss: 2.1951\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 736us/step - loss: 2.5815 - val_loss: 2.3244\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 727us/step - loss: 2.5489 - val_loss: 2.4284\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 732us/step - loss: 2.5508 - val_loss: 2.4693\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 780us/step - loss: 2.5253 - val_loss: 2.2259\n",
      "573/573 [==============================] - 0s 529us/step - loss: 2.2321\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 832us/step - loss: 8.3626 - val_loss: 8.3310\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 721us/step - loss: 8.2659 - val_loss: 8.2449\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 781us/step - loss: 8.2648 - val_loss: 8.2896\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: 8.2591 - val_loss: 8.3075\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 841us/step - loss: 8.2607 - val_loss: 8.3043\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 761us/step - loss: 8.2486 - val_loss: 8.2327\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 699us/step - loss: 8.2529 - val_loss: 8.2413\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 741us/step - loss: 8.2532 - val_loss: 8.3294\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 739us/step - loss: 8.2504 - val_loss: 8.2445\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 745us/step - loss: 8.2502 - val_loss: 8.2470\n",
      "573/573 [==============================] - 0s 513us/step - loss: 8.3079\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 766us/step - loss: 8.4790 - val_loss: 8.2336\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 747us/step - loss: 8.2484 - val_loss: 8.2349\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 736us/step - loss: 8.2491 - val_loss: 8.2311\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 715us/step - loss: 8.2477 - val_loss: 8.2359\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 710us/step - loss: 8.2492 - val_loss: 8.2294\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 728us/step - loss: 8.2471 - val_loss: 8.2324\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 714us/step - loss: 8.2488 - val_loss: 8.2292\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 715us/step - loss: 8.2484 - val_loss: 8.2417\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 714us/step - loss: 8.2478 - val_loss: 8.2301\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 716us/step - loss: 8.2468 - val_loss: 8.2294\n",
      "573/573 [==============================] - 0s 495us/step - loss: 8.2699\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 716us/step - loss: 9.7341 - val_loss: 8.2307\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 659us/step - loss: 8.2842 - val_loss: 8.2294\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 676us/step - loss: 8.2828 - val_loss: 8.2293\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 654us/step - loss: 8.2839 - val_loss: 8.2301\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 671us/step - loss: 8.2826 - val_loss: 8.2303\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 664us/step - loss: 8.2835 - val_loss: 8.2298\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 676us/step - loss: 8.2843 - val_loss: 8.2294\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 675us/step - loss: 8.2844 - val_loss: 8.2296\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 686us/step - loss: 8.2839 - val_loss: 8.2301\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 668us/step - loss: 8.2839 - val_loss: 8.2307\n",
      "573/573 [==============================] - 0s 506us/step - loss: 8.1916\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 769us/step - loss: 9.6908 - val_loss: 8.2293\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 659us/step - loss: 8.2312 - val_loss: 8.2293\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 667us/step - loss: 8.2304 - val_loss: 8.2302\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 655us/step - loss: 8.2303 - val_loss: 8.2296\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 682us/step - loss: 8.2308 - val_loss: 8.2304\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 652us/step - loss: 8.2306 - val_loss: 8.2292\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 659us/step - loss: 8.2307 - val_loss: 8.2310\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 652us/step - loss: 8.2313 - val_loss: 8.2295\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 669us/step - loss: 8.2310 - val_loss: 8.2293\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 686us/step - loss: 8.2302 - val_loss: 8.2320\n",
      "573/573 [==============================] - 0s 486us/step - loss: 8.2962\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 721us/step - loss: 9.7025 - val_loss: 8.2300\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 660us/step - loss: 8.2436 - val_loss: 8.2304\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 662us/step - loss: 8.2436 - val_loss: 8.2292\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 673us/step - loss: 8.2438 - val_loss: 8.2294\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 662us/step - loss: 8.2431 - val_loss: 8.2300\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 663us/step - loss: 8.2439 - val_loss: 8.2292\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 661us/step - loss: 8.2434 - val_loss: 8.2293\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 663us/step - loss: 8.2438 - val_loss: 8.2297\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 662us/step - loss: 8.2435 - val_loss: 8.2293\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 662us/step - loss: 8.2434 - val_loss: 8.2298\n",
      "573/573 [==============================] - 0s 510us/step - loss: 8.2724\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 810us/step - loss: 2.5137 - val_loss: 1.7848\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 765us/step - loss: 1.7565 - val_loss: 1.7193\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 762us/step - loss: 1.6326 - val_loss: 2.0853\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 767us/step - loss: 1.5505 - val_loss: 1.5251\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 762us/step - loss: 1.4825 - val_loss: 1.5310\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 769us/step - loss: 1.4455 - val_loss: 1.4608\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 755us/step - loss: 1.3818 - val_loss: 1.4055\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 778us/step - loss: 1.3521 - val_loss: 1.4704\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 763us/step - loss: 1.3314 - val_loss: 1.4239\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 763us/step - loss: 1.3089 - val_loss: 1.4550\n",
      "573/573 [==============================] - 0s 509us/step - loss: 1.4634\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 808us/step - loss: 2.6818 - val_loss: 1.8585\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 753us/step - loss: 1.7887 - val_loss: 1.6414\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 766us/step - loss: 1.6674 - val_loss: 1.6878\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 765us/step - loss: 1.5973 - val_loss: 1.4989\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 766us/step - loss: 1.5311 - val_loss: 1.4927\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 783us/step - loss: 1.4716 - val_loss: 1.4737\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 767us/step - loss: 1.4282 - val_loss: 1.3839\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 766us/step - loss: 1.3806 - val_loss: 1.4060\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 765us/step - loss: 1.3538 - val_loss: 1.4360\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 763us/step - loss: 1.3434 - val_loss: 1.4792\n",
      "573/573 [==============================] - 0s 524us/step - loss: 1.5393\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 800us/step - loss: 2.6788 - val_loss: 1.8322\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 746us/step - loss: 1.8448 - val_loss: 1.6427\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 770us/step - loss: 1.6553 - val_loss: 1.6253\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 748us/step - loss: 1.5658 - val_loss: 1.5609\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 762us/step - loss: 1.4959 - val_loss: 1.5371\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 748us/step - loss: 1.4487 - val_loss: 1.5337\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 762us/step - loss: 1.4155 - val_loss: 1.4719\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 759us/step - loss: 1.3935 - val_loss: 1.4872\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 762us/step - loss: 1.3605 - val_loss: 1.3928\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 754us/step - loss: 1.3527 - val_loss: 1.4909\n",
      "573/573 [==============================] - 0s 507us/step - loss: 1.5064\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 766us/step - loss: 2.7752 - val_loss: 1.8385\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 747us/step - loss: 1.8545 - val_loss: 2.2644\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 741us/step - loss: 1.7436 - val_loss: 1.6393\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 730us/step - loss: 1.6773 - val_loss: 1.7145\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 729us/step - loss: 1.6132 - val_loss: 1.6083\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 724us/step - loss: 1.5827 - val_loss: 1.6082\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 724us/step - loss: 1.5245 - val_loss: 1.7370\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 734us/step - loss: 1.5034 - val_loss: 1.6593\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 741us/step - loss: 1.4681 - val_loss: 1.5932\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 734us/step - loss: 1.4525 - val_loss: 1.5452\n",
      "573/573 [==============================] - 0s 496us/step - loss: 1.5275\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 764us/step - loss: 3.2473 - val_loss: 2.0758\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 727us/step - loss: 2.0480 - val_loss: 1.9957\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 730us/step - loss: 1.8083 - val_loss: 1.6832\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 737us/step - loss: 1.6752 - val_loss: 1.6131\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 745us/step - loss: 1.5879 - val_loss: 1.5827\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 762us/step - loss: 1.5345 - val_loss: 1.4938\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 741us/step - loss: 1.4971 - val_loss: 1.4992\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 738us/step - loss: 1.4502 - val_loss: 1.4366\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 748us/step - loss: 1.4236 - val_loss: 1.5336\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 736us/step - loss: 1.4111 - val_loss: 1.5044\n",
      "573/573 [==============================] - 0s 516us/step - loss: 1.5183\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 762us/step - loss: 2.5262 - val_loss: 1.7039\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 700us/step - loss: 1.7690 - val_loss: 1.8038\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 702us/step - loss: 1.6585 - val_loss: 1.5326\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 712us/step - loss: 1.5864 - val_loss: 1.5441\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 705us/step - loss: 1.5606 - val_loss: 1.6536\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 717us/step - loss: 1.5179 - val_loss: 1.6445\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 705us/step - loss: 1.4953 - val_loss: 1.4728\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 710us/step - loss: 1.4664 - val_loss: 1.4427\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 714us/step - loss: 1.4508 - val_loss: 1.5522\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 709us/step - loss: 1.4374 - val_loss: 1.4886\n",
      "573/573 [==============================] - 0s 496us/step - loss: 1.4500\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 2s 880us/step - loss: 8.2005 - val_loss: 2.1794\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 833us/step - loss: 2.1131 - val_loss: 2.0138\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 814us/step - loss: 1.9664 - val_loss: 1.8775\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 832us/step - loss: 1.8834 - val_loss: 1.8467\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 835us/step - loss: 1.8252 - val_loss: 1.7872\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 839us/step - loss: 1.7693 - val_loss: 1.7592\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 817us/step - loss: 1.7180 - val_loss: 1.7066\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 856us/step - loss: 1.6786 - val_loss: 1.6795\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 818us/step - loss: 1.6424 - val_loss: 1.6741\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 831us/step - loss: 1.6202 - val_loss: 1.6385\n",
      "573/573 [==============================] - 0s 544us/step - loss: 1.6430\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 879us/step - loss: 10.3132 - val_loss: 2.3068\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 819us/step - loss: 2.2021 - val_loss: 2.0215\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 816us/step - loss: 1.9849 - val_loss: 1.8771\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 836us/step - loss: 1.8671 - val_loss: 1.8288\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 828us/step - loss: 1.7930 - val_loss: 1.7542\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 843us/step - loss: 1.7405 - val_loss: 1.6818\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 830us/step - loss: 1.7041 - val_loss: 1.6905\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 842us/step - loss: 1.6684 - val_loss: 1.6311\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 824us/step - loss: 1.6414 - val_loss: 1.6155\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 833us/step - loss: 1.6141 - val_loss: 1.5979\n",
      "573/573 [==============================] - 0s 561us/step - loss: 1.6438 0s - loss: \n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 874us/step - loss: 3.8907 - val_loss: 2.3645\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 815us/step - loss: 2.2849 - val_loss: 2.0579\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 833us/step - loss: 2.0246 - val_loss: 1.8907\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 840us/step - loss: 1.8847 - val_loss: 1.8644\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 848us/step - loss: 1.8104 - val_loss: 1.7961\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 822us/step - loss: 1.7476 - val_loss: 1.7679\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 843us/step - loss: 1.7015 - val_loss: 1.6807\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 839us/step - loss: 1.6607 - val_loss: 1.6518\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 855us/step - loss: 1.6270 - val_loss: 1.6300\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 837us/step - loss: 1.5968 - val_loss: 1.6035\n",
      "573/573 [==============================] - 0s 544us/step - loss: 1.6045\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 627us/step - loss: 28.5077 - val_loss: 28.4792\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 595us/step - loss: 28.5077 - val_loss: 28.4792\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 600us/step - loss: 28.5077 - val_loss: 28.4792\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 590us/step - loss: 28.5077 - val_loss: 28.4792\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 589us/step - loss: 28.5077 - val_loss: 28.4792\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 599us/step - loss: 28.5077 - val_loss: 28.4792\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 607us/step - loss: 28.5077 - val_loss: 28.4792\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 605us/step - loss: 28.5077 - val_loss: 28.4792\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 600us/step - loss: 28.5077 - val_loss: 28.4792\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 617us/step - loss: 28.5077 - val_loss: 28.4792\n",
      "573/573 [==============================] - 0s 502us/step - loss: 28.4902\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 644us/step - loss: 28.3869 - val_loss: 28.4792\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 592us/step - loss: 28.3869 - val_loss: 28.4792\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 608us/step - loss: 28.3869 - val_loss: 28.4792\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 601us/step - loss: 28.3869 - val_loss: 28.4792\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 603us/step - loss: 28.3869 - val_loss: 28.4792\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 599us/step - loss: 28.3869 - val_loss: 28.4792\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 604us/step - loss: 28.3869 - val_loss: 28.4792\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 602us/step - loss: 28.3869 - val_loss: 28.4792\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 605us/step - loss: 28.3869 - val_loss: 28.4792\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 609us/step - loss: 28.3869 - val_loss: 28.4792\n",
      "573/573 [==============================] - 0s 460us/step - loss: 28.7319\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 634us/step - loss: 28.6111 - val_loss: 28.4792\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 617us/step - loss: 28.6111 - val_loss: 28.4792\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 603us/step - loss: 28.6111 - val_loss: 28.4792\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 602us/step - loss: 28.6111 - val_loss: 28.4792\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 601us/step - loss: 28.6111 - val_loss: 28.4792\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 604us/step - loss: 28.6111 - val_loss: 28.4792\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 604us/step - loss: 28.6111 - val_loss: 28.4792\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 600us/step - loss: 28.6111 - val_loss: 28.4792\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 601us/step - loss: 28.6111 - val_loss: 28.4792\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 599us/step - loss: 28.6111 - val_loss: 28.4792\n",
      "573/573 [==============================] - 0s 455us/step - loss: 28.2835\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 748us/step - loss: 2.4621 - val_loss: 1.9250\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 717us/step - loss: 1.8041 - val_loss: 1.7638\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 714us/step - loss: 1.7027 - val_loss: 1.6472\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 717us/step - loss: 1.6396 - val_loss: 1.8319\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 722us/step - loss: 1.5981 - val_loss: 1.6153\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 714us/step - loss: 1.5546 - val_loss: 1.6662\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 719us/step - loss: 1.5335 - val_loss: 1.6050\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 726us/step - loss: 1.5156 - val_loss: 1.6413\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 721us/step - loss: 1.4987 - val_loss: 1.5195\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 723us/step - loss: 1.4803 - val_loss: 1.5841\n",
      "573/573 [==============================] - 0s 508us/step - loss: 1.5717\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 767us/step - loss: 2.7077 - val_loss: 2.4292\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 714us/step - loss: 2.0586 - val_loss: 1.9228\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 748us/step - loss: 1.8457 - val_loss: 2.2643\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 751us/step - loss: 1.7492 - val_loss: 1.6898\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 740us/step - loss: 1.7057 - val_loss: 1.7395\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 746us/step - loss: 1.6522 - val_loss: 1.6249\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 741us/step - loss: 1.6150 - val_loss: 1.5774\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 741us/step - loss: 1.5700 - val_loss: 1.6774\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 763us/step - loss: 1.5544 - val_loss: 1.5249\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 739us/step - loss: 1.5182 - val_loss: 1.4786\n",
      "573/573 [==============================] - 0s 509us/step - loss: 1.5388\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 758us/step - loss: 2.4666 - val_loss: 2.0080\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 727us/step - loss: 1.8608 - val_loss: 1.6742\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 765us/step - loss: 1.7399 - val_loss: 1.6963\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 769us/step - loss: 1.6699 - val_loss: 2.0255\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 725us/step - loss: 1.6189 - val_loss: 1.5695\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 745us/step - loss: 1.5747 - val_loss: 1.5581\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 738us/step - loss: 1.5386 - val_loss: 1.5761\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 721us/step - loss: 1.5127 - val_loss: 1.5852\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 726us/step - loss: 1.4947 - val_loss: 1.7191\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 727us/step - loss: 1.4537 - val_loss: 1.8238\n",
      "573/573 [==============================] - ETA: 0s - loss: 1.865 - 0s 519us/step - loss: 1.8407\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 829us/step - loss: 3.3211 - val_loss: 2.2805\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 804us/step - loss: 2.1667 - val_loss: 1.9888\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 798us/step - loss: 1.9704 - val_loss: 1.8586\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 800us/step - loss: 1.8774 - val_loss: 1.8316\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 813us/step - loss: 1.8148 - val_loss: 1.8214\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 804us/step - loss: 1.7640 - val_loss: 1.9066\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 818us/step - loss: 1.7179 - val_loss: 1.6875\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 805us/step - loss: 1.6816 - val_loss: 1.6910\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 803us/step - loss: 1.6496 - val_loss: 1.6376\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 812us/step - loss: 1.6180 - val_loss: 1.6178\n",
      "573/573 [==============================] - 0s 521us/step - loss: 1.6678\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 836us/step - loss: 3.3793 - val_loss: 2.3155\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 802us/step - loss: 2.1766 - val_loss: 1.9543\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 803us/step - loss: 1.9595 - val_loss: 1.8382\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 797us/step - loss: 1.8618 - val_loss: 1.7713\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 808us/step - loss: 1.8032 - val_loss: 1.7352\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 793us/step - loss: 1.7489 - val_loss: 1.7087\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 821us/step - loss: 1.7067 - val_loss: 1.6706\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 796us/step - loss: 1.6726 - val_loss: 1.6521\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 803us/step - loss: 1.6432 - val_loss: 1.6714\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 804us/step - loss: 1.6181 - val_loss: 1.6034\n",
      "573/573 [==============================] - 0s 523us/step - loss: 1.6525\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 1s 859us/step - loss: 3.8810 - val_loss: 2.4398\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 1s 785us/step - loss: 2.3326 - val_loss: 2.0920\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 1s 795us/step - loss: 2.0903 - val_loss: 1.9277\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 1s 797us/step - loss: 1.9358 - val_loss: 1.8292\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 1s 793us/step - loss: 1.8402 - val_loss: 1.7778\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 1s 793us/step - loss: 1.7736 - val_loss: 1.7262\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 1s 802us/step - loss: 1.7264 - val_loss: 1.7126\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 1s 797us/step - loss: 1.6879 - val_loss: 1.6875\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 1s 808us/step - loss: 1.6552 - val_loss: 1.6659\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 1s 791us/step - loss: 1.6278 - val_loss: 1.6237\n",
      "573/573 [==============================] - 0s 521us/step - loss: 1.6204\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 1s 746us/step - loss: 3.5079 - val_loss: 2.1690\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 1s 711us/step - loss: 2.1177 - val_loss: 1.9358\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 1s 715us/step - loss: 1.8465 - val_loss: 1.6580\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 1s 716us/step - loss: 1.7015 - val_loss: 1.5778\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 1s 720us/step - loss: 1.6435 - val_loss: 1.5738\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 1s 712us/step - loss: 1.6012 - val_loss: 1.6531\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 1s 714us/step - loss: 1.5644 - val_loss: 1.5483\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 1s 723us/step - loss: 1.5507 - val_loss: 1.5510\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 1s 705us/step - loss: 1.5389 - val_loss: 1.7883\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 1s 706us/step - loss: 1.5262 - val_loss: 1.5105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000027D60C3AE10>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000027D46EABFD0>,\n",
       "                                        'n_hidden': [5, 3, 2],\n",
       "                                        'n_neurons': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.fit(x_train, y_train, epochs = 10, validation_data = (x_valid, y_valid), callbacks = [keras.callbacks.EarlyStopping(patience = 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f01bc3a-f6fd-4c40-a008-f8dc3298358b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
