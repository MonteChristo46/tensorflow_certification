{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19cf51ee-3424-4893-ad9e-06174cb5921d",
   "metadata": {},
   "source": [
    "# The functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e16c8-c8df-4e4b-b8a8-8ee0ad7ef6cb",
   "metadata": {},
   "source": [
    "## Wide and Deep Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2365e-cb45-4620-8e4a-ea910710ace3",
   "metadata": {},
   "source": [
    "<img src = \"../../img/0000.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80931e03-2601-40f9-b115-b02364206bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb43abf-b387-4f74-968b-541c45bc0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6d2c6-6404-4510-a3fe-a1c5cc927f9b",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07752ac-17d2-4a9e-bc68-91ca52d11d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20689526-4aed-4ad2-8efa-16ca0adaf389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a3622-d798-4100-a732-bf13efe8437f",
   "metadata": {},
   "source": [
    "## Train, Test & Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7df2f8b-55dd-4aa3-ab95-ec32d0aaece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "439090d5-7c37-4da0-8c35-4bd93d641000",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid, x_train, y_train = x_train[:5000], y_train[:5000], x_train[5000:], y_train[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a4114-6bd8-451d-ae8b-aa6aa7f65840",
   "metadata": {},
   "source": [
    "## Scaling Data\n",
    "Scaling means that we gonna normalize the range of variables (feature space). For e.g. that all values are between 0-1\n",
    "\n",
    "Scaling is in some machine learning tasks essentiel: \n",
    "\n",
    "__1. When calculating distances__ (e.g. Euclidian Distance)  \n",
    "__2. When using Gradient Descent Optimizers__ (Without scaling optimizer may doesn't find optimum and optimization takes much longer..)  \n",
    "__3. When Regularization is used__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b605aa-7083-4577-9e0a-2023f65fe16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_valid = scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af2c70-9fc3-47eb-8f12-c19b88f31796",
   "metadata": {},
   "source": [
    "## Building the model (1 Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8807c3-9725-40fb-a76c-3f82cb058908",
   "metadata": {},
   "source": [
    "### First define layers  (No data processed yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c76f9b-1ff9-4cef-9885-9f11c4642f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape = x_train.shape[1:])\n",
    "hidden_1 = keras.layers.Dense(30, activation=keras.activations.relu)(input_)\n",
    "hidden_2 = keras.layers.Dense(30, activation = keras.activations.relu)(hidden_1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden_2])\n",
    "out = keras.layers.Dense(1)(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5719439c-42db-4785-8589-3abb2df43726",
   "metadata": {},
   "source": [
    "### Declaring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe83868-d6f6-4d1f-af7a-681f219110df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(inputs = [input_], outputs = [out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01287e-2a67-4f94-822c-d2a4768513e5",
   "metadata": {},
   "source": [
    "### Compiling & Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f39f173b-7a74-4544-bde0-4f61c1621731",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate = 1e-3), loss = \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19383ed4-dc53-4873-9ec6-3dfa6e8812cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "328/328 [==============================] - 0s 593us/step - loss: 1.6466\n",
      "Epoch 2/30\n",
      "328/328 [==============================] - 0s 567us/step - loss: 0.7006\n",
      "Epoch 3/30\n",
      "328/328 [==============================] - 0s 572us/step - loss: 0.6507\n",
      "Epoch 4/30\n",
      "328/328 [==============================] - 0s 590us/step - loss: 0.6225\n",
      "Epoch 5/30\n",
      "328/328 [==============================] - 0s 575us/step - loss: 0.6019\n",
      "Epoch 6/30\n",
      "328/328 [==============================] - 0s 587us/step - loss: 0.5844\n",
      "Epoch 7/30\n",
      "328/328 [==============================] - 0s 563us/step - loss: 0.5695\n",
      "Epoch 8/30\n",
      "328/328 [==============================] - 0s 544us/step - loss: 0.5568\n",
      "Epoch 9/30\n",
      "328/328 [==============================] - 0s 547us/step - loss: 0.5460\n",
      "Epoch 10/30\n",
      "328/328 [==============================] - 0s 554us/step - loss: 0.5361\n",
      "Epoch 11/30\n",
      "328/328 [==============================] - 0s 529us/step - loss: 0.5280\n",
      "Epoch 12/30\n",
      "328/328 [==============================] - 0s 550us/step - loss: 0.5205\n",
      "Epoch 13/30\n",
      "328/328 [==============================] - 0s 556us/step - loss: 0.5142\n",
      "Epoch 14/30\n",
      "328/328 [==============================] - 0s 541us/step - loss: 0.5080\n",
      "Epoch 15/30\n",
      "328/328 [==============================] - 0s 541us/step - loss: 0.5028\n",
      "Epoch 16/30\n",
      "328/328 [==============================] - 0s 547us/step - loss: 0.4981\n",
      "Epoch 17/30\n",
      "328/328 [==============================] - 0s 600us/step - loss: 0.4938\n",
      "Epoch 18/30\n",
      "328/328 [==============================] - 0s 575us/step - loss: 0.4891\n",
      "Epoch 19/30\n",
      "328/328 [==============================] - 0s 547us/step - loss: 0.4865\n",
      "Epoch 20/30\n",
      "328/328 [==============================] - 0s 564us/step - loss: 0.4833\n",
      "Epoch 21/30\n",
      "328/328 [==============================] - 0s 572us/step - loss: 0.4798\n",
      "Epoch 22/30\n",
      "328/328 [==============================] - 0s 578us/step - loss: 0.4772\n",
      "Epoch 23/30\n",
      "328/328 [==============================] - 0s 560us/step - loss: 0.4744\n",
      "Epoch 24/30\n",
      "328/328 [==============================] - 0s 575us/step - loss: 0.4721\n",
      "Epoch 25/30\n",
      "328/328 [==============================] - 0s 566us/step - loss: 0.4698\n",
      "Epoch 26/30\n",
      "328/328 [==============================] - 0s 557us/step - loss: 0.4685\n",
      "Epoch 27/30\n",
      "328/328 [==============================] - 0s 581us/step - loss: 0.4659\n",
      "Epoch 28/30\n",
      "328/328 [==============================] - 0s 563us/step - loss: 0.4644\n",
      "Epoch 29/30\n",
      "328/328 [==============================] - 0s 590us/step - loss: 0.4628\n",
      "Epoch 30/30\n",
      "328/328 [==============================] - 0s 569us/step - loss: 0.4614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d120fc9978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3608f880-b77c-40d6-91e4-72bc74dd955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 454us/step - loss: 0.4475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4475395381450653"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7947d8-f972-4993-bc08-e779027a3571",
   "metadata": {},
   "source": [
    "## Models with multiple inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8ef48-20cc-4152-9ab7-af31facb8768",
   "metadata": {},
   "source": [
    "<img src = \"../../img/0001.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa694e-c830-43eb-bbfe-e38b18b29654",
   "metadata": {},
   "source": [
    "__Notes__:  \n",
    "1. We split the available features. One part goes to Input_A one part to Input_B\n",
    "2. 5 features are sent to the wide path\n",
    "3. 6 features are send to the deep path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b20d75f3-9414-4eaa-a023-89ae1dd81b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = keras.layers.Input(shape=[5])\n",
    "input_b = keras.layers.Input(shape=[6])\n",
    "\n",
    "hidden_1 = keras.layers.Dense(30, activation = keras.activations.relu)(input_b)\n",
    "hidden_2 = keras.layers.Dense(30, activation = keras.activations.relu)(hidden_1)\n",
    "\n",
    "concat = keras.layers.Concatenate()([input_a, hidden_2])\n",
    "\n",
    "out = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = keras.models.Model(inputs = [input_a, input_b], outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "088e4786-de5c-446d-89b8-dad94bc7543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = x_train[:, :5], x_train[:, 2:]\n",
    "X_valid_A, X_valid_B = x_valid[:, :5], x_valid[:, 2:]\n",
    "X_test_A, X_test_B = x_test[:, :5], x_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628c82b7-d316-490c-93f4-af29749f5081",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate = 1e-3), loss=keras.losses.mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75182892-ebcc-4100-acbc-fc2f72893d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 2.1389 - val_loss: 0.9998\n",
      "Epoch 2/30\n",
      "328/328 [==============================] - 0s 844us/step - loss: 0.9437 - val_loss: 0.8081\n",
      "Epoch 3/30\n",
      "328/328 [==============================] - 0s 838us/step - loss: 0.7741 - val_loss: 0.7230\n",
      "Epoch 4/30\n",
      "328/328 [==============================] - 0s 829us/step - loss: 0.7054 - val_loss: 0.6756\n",
      "Epoch 5/30\n",
      "328/328 [==============================] - 0s 823us/step - loss: 0.6633 - val_loss: 0.6417\n",
      "Epoch 6/30\n",
      "328/328 [==============================] - 0s 810us/step - loss: 0.6330 - val_loss: 0.6164\n",
      "Epoch 7/30\n",
      "328/328 [==============================] - 0s 835us/step - loss: 0.6096 - val_loss: 0.5958\n",
      "Epoch 8/30\n",
      "328/328 [==============================] - 0s 854us/step - loss: 0.5904 - val_loss: 0.5794\n",
      "Epoch 9/30\n",
      "328/328 [==============================] - 0s 829us/step - loss: 0.5743 - val_loss: 0.5640\n",
      "Epoch 10/30\n",
      "328/328 [==============================] - 0s 813us/step - loss: 0.5603 - val_loss: 0.5530\n",
      "Epoch 11/30\n",
      "328/328 [==============================] - 0s 844us/step - loss: 0.5483 - val_loss: 0.5399\n",
      "Epoch 12/30\n",
      "328/328 [==============================] - 0s 824us/step - loss: 0.5378 - val_loss: 0.5300\n",
      "Epoch 13/30\n",
      "328/328 [==============================] - 0s 853us/step - loss: 0.5290 - val_loss: 0.5216\n",
      "Epoch 14/30\n",
      "328/328 [==============================] - 0s 835us/step - loss: 0.5211 - val_loss: 0.5140\n",
      "Epoch 15/30\n",
      "328/328 [==============================] - 0s 846us/step - loss: 0.5144 - val_loss: 0.5072\n",
      "Epoch 16/30\n",
      "328/328 [==============================] - 0s 860us/step - loss: 0.5087 - val_loss: 0.5045\n",
      "Epoch 17/30\n",
      "328/328 [==============================] - 0s 840us/step - loss: 0.5037 - val_loss: 0.4973\n",
      "Epoch 18/30\n",
      "328/328 [==============================] - 0s 827us/step - loss: 0.4997 - val_loss: 0.4945\n",
      "Epoch 19/30\n",
      "328/328 [==============================] - 0s 841us/step - loss: 0.4960 - val_loss: 0.4889\n",
      "Epoch 20/30\n",
      "328/328 [==============================] - 0s 825us/step - loss: 0.4926 - val_loss: 0.4879\n",
      "Epoch 21/30\n",
      "328/328 [==============================] - 0s 838us/step - loss: 0.4897 - val_loss: 0.4844\n",
      "Epoch 22/30\n",
      "328/328 [==============================] - 0s 820us/step - loss: 0.4870 - val_loss: 0.4811\n",
      "Epoch 23/30\n",
      "328/328 [==============================] - 0s 832us/step - loss: 0.4845 - val_loss: 0.4762\n",
      "Epoch 24/30\n",
      "328/328 [==============================] - 0s 838us/step - loss: 0.4823 - val_loss: 0.4737\n",
      "Epoch 25/30\n",
      "328/328 [==============================] - 0s 813us/step - loss: 0.4803 - val_loss: 0.4715\n",
      "Epoch 26/30\n",
      "328/328 [==============================] - 0s 807us/step - loss: 0.4785 - val_loss: 0.4700\n",
      "Epoch 27/30\n",
      "328/328 [==============================] - 0s 829us/step - loss: 0.4769 - val_loss: 0.4680\n",
      "Epoch 28/30\n",
      "328/328 [==============================] - 0s 859us/step - loss: 0.4752 - val_loss: 0.4669\n",
      "Epoch 29/30\n",
      "328/328 [==============================] - 0s 835us/step - loss: 0.4736 - val_loss: 0.4648\n",
      "Epoch 30/30\n",
      "328/328 [==============================] - 0s 795us/step - loss: 0.4724 - val_loss: 0.4634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d1292fe668>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit((X_train_A,X_train_B), y_train, epochs = 30, validation_data = ((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b3aa89e-c687-4663-a691-b337c6f243d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 481us/step - loss: 0.4565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45645880699157715"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_test_A, X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e70ea80-7c18-4d91-818d-87da02fdcb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9824607],\n",
       "       [2.414165 ],\n",
       "       [2.2013783]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03a7d5-7b48-419e-9a1c-f2925187ae67",
   "metadata": {},
   "source": [
    "## Models with multiple outputs\n",
    "\n",
    "Sometimes we also need models with multiple outputs: \n",
    "\n",
    "- Task demands it (locate and classifiy bounding boxes)\n",
    "- Similar independent tasks based on the same data. \n",
    "- Multiclass classifications on pictur\n",
    "- Regularization techniques\n",
    "\n",
    "\n",
    "It's implemented equivalent to the implementation above with multiple inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758ed2c-a335-4e3c-8113-e873ffaab352",
   "metadata": {},
   "source": [
    "<img src = \"../../img/1016.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d0301-e384-4149-92b4-a4ea849eae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
